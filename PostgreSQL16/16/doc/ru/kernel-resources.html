<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html xmlns="http://www.w3.org/1999/xhtml"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8" /><title>19.4. Управление ресурсами ядра</title><link rel="stylesheet" type="text/css" href="stylesheet.css" /><link rev="made" href="pgsql-docs@lists.postgresql.org" /><meta name="generator" content="DocBook XSL Stylesheets Vsnapshot" /><link rel="prev" href="server-start.html" title="19.3. Запуск сервера баз данных" /><link rel="next" href="server-shutdown.html" title="19.5. Выключение сервера" /></head><body id="docContent" class="container-fluid col-10"><div class="navheader"><table width="100%" summary="Navigation header"><tr><th colspan="5" align="center">19.4. Управление ресурсами ядра</th></tr><tr><td width="10%" align="left"><a accesskey="p" href="server-start.html" title="19.3. Запуск сервера баз данных">Пред.</a> </td><td width="10%" align="left"><a accesskey="u" href="runtime.html" title="Глава 19. Подготовка к работе и сопровождение сервера">Наверх</a></td><th width="60%" align="center">Глава 19. Подготовка к работе и сопровождение сервера</th><td width="10%" align="right"><a accesskey="h" href="index.html" title="Документация к PostgreSQL 16.3">Начало</a></td><td width="10%" align="right"> <a accesskey="n" href="server-shutdown.html" title="19.5. Выключение сервера">След.</a></td></tr></table><hr /></div><div class="sect1" id="KERNEL-RESOURCES"><div class="titlepage"><div><div><h2 class="title" style="clear: both">19.4. Управление ресурсами ядра <a href="#KERNEL-RESOURCES" class="id_link">#</a></h2></div></div></div><div class="toc"><dl class="toc"><dt><span class="sect2"><a href="kernel-resources.html#SYSVIPC">19.4.1. Разделяемая память и семафоры</a></span></dt><dt><span class="sect2"><a href="kernel-resources.html#SYSTEMD-REMOVEIPC">19.4.2. RemoveIPC в systemd</a></span></dt><dt><span class="sect2"><a href="kernel-resources.html#KERNEL-RESOURCES-LIMITS">19.4.3. Ограничения ресурсов</a></span></dt><dt><span class="sect2"><a href="kernel-resources.html#LINUX-MEMORY-OVERCOMMIT">19.4.4. Чрезмерное выделение памяти в Linux</a></span></dt><dt><span class="sect2"><a href="kernel-resources.html#LINUX-HUGE-PAGES">19.4.5. Огромные страницы в Linux</a></span></dt></dl></div><p><span class="productname">PostgreSQL</span> иногда может исчерпывать некоторые ресурсы операционной системы до предела, особенно при запуске нескольких копий сервера в одной системе или при работе с очень большими базами. В этом разделе описываются ресурсы ядра, которые использует <span class="productname">PostgreSQL</span>, и подходы к решению проблем, связанных с ограниченностью этих ресурсов.</p><div class="sect2" id="SYSVIPC"><div class="titlepage"><div><div><h3 class="title">19.4.1. Разделяемая память и семафоры <a href="#SYSVIPC" class="id_link">#</a></h3></div></div></div><a id="id-1.6.6.7.3.2" class="indexterm"></a><a id="id-1.6.6.7.3.3" class="indexterm"></a><p><span class="productname">PostgreSQL</span> требует, чтобы операционная система предоставляла средства межпроцессного взаимодействия (<acronym class="acronym">IPC</acronym>), в частности, разделяемую память и семафоры. Системы семейства Unix обычно предоставляют функции <acronym class="acronym">IPC</acronym> в стиле <span class="quote">«<span class="quote"><span class="systemitem">System V</span></span>»</span> или функции <acronym class="acronym">IPC</acronym> в стиле <span class="quote">«<span class="quote"><span class="systemitem">POSIX</span></span>»</span> или и те, и другие. В <span class="systemitem">Windows</span> эти механизмы реализованы по-другому, но здесь это не рассматривается.</p><p>По умолчанию <span class="productname">PostgreSQL</span> запрашивает очень небольшой объём разделяемой памяти System V и намного больший объём анонимной разделяемой памяти <code class="function">mmap</code>. Возможен также вариант использования одной большой области памяти System V (см. <a class="xref" href="runtime-config-resource.html#GUC-SHARED-MEMORY-TYPE">shared_memory_type</a>). Помимо этого при запуске сервера создаётся значительное количество семафоров (в стиле System V или POSIX). В настоящее время семафоры POSIX используются в системах Linux и FreeBSD, а на других платформах используются семафоры System V.</p><p>Функции <acronym class="acronym">IPC</acronym> в стиле System V обычно сталкиваются с лимитами на уровне системы. Когда <span class="productname">PostgreSQL</span> превышает один из этих лимитов, сервер отказывается запускаться, но должен выдать полезное сообщение, говорящее об ошибке и о том, что с ней делать. (См. также <a class="xref" href="server-start.html#SERVER-START-FAILURES" title="19.3.1. Сбои при запуске сервера">Подраздел 19.3.1</a>.) Соответствующие параметры ядра в разных системах называются аналогично (они перечислены в <a class="xref" href="kernel-resources.html#SYSVIPC-PARAMETERS" title="Таблица 19.1. Параметры IPC в стиле System V">Таблице 19.1</a>), но устанавливаются по-разному. Ниже предлагаются способы их изменения для некоторых систем.</p><div class="table" id="SYSVIPC-PARAMETERS"><p class="title"><strong>Таблица 19.1. Параметры <acronym class="acronym">IPC</acronym> в стиле <span class="systemitem">System V</span></strong></p><div class="table-contents"><table class="table" summary="Параметры IPC в стиле System V" border="1"><colgroup><col class="col1" /><col class="col2" /><col class="col3" /></colgroup><thead><tr><th>Name</th><th>Описание</th><th>Значения, необходимые для запуска одного экземпляра <span class="productname">PostgreSQL</span></th></tr></thead><tbody><tr><td><code class="varname">SHMMAX</code></td><td>Максимальный размер сегмента разделяемой памяти (в байтах)</td><td>как минимум 1 КБ, но значение по умолчанию обычно гораздо больше</td></tr><tr><td><code class="varname">SHMMIN</code></td><td>Минимальный размер сегмента разделяемой памяти (в байтах)</td><td>1</td></tr><tr><td><code class="varname">SHMALL</code></td><td>Общий объём доступной разделяемой памяти (в байтах или страницах)</td><td>если в байтах, то же, что и <code class="varname">SHMMAX</code>; если в страницах, то <code class="literal">ceil(SHMMAX/PAGE_SIZE)</code>, плюс потребность других приложений</td></tr><tr><td><code class="varname">SHMSEG</code></td><td>Максимальное число сегментов разделяемой памяти для процесса</td><td>требуется только 1 сегмент, но значение по умолчанию гораздо больше</td></tr><tr><td><code class="varname">SHMMNI</code></td><td>Максимальное число сегментов разделяемой памяти для всей системы</td><td>как <code class="varname">SHMSEG</code> плюс потребность других приложений</td></tr><tr><td><code class="varname">SEMMNI</code></td><td>Максимальное число идентификаторов семафоров (т. е., их наборов)</td><td>как минимум <code class="literal">ceil((max_connections + autovacuum_max_workers + max_wal_senders + max_worker_processes + 5) / 16)</code> плюс потребность других приложений</td></tr><tr><td><code class="varname">SEMMNS</code></td><td>Максимальное число семафоров для всей системы</td><td><code class="literal">ceil((max_connections + autovacuum_max_workers + max_wal_senders + max_worker_processes + 5) / 16) * 17</code> плюс потребность других приложений</td></tr><tr><td><code class="varname">SEMMSL</code></td><td>Максимальное число семафоров в наборе</td><td>не меньше 17</td></tr><tr><td><code class="varname">SEMMAP</code></td><td>Число записей в карте семафоров</td><td>см. текст</td></tr><tr><td><code class="varname">SEMVMX</code></td><td>Максимальное значение семафора</td><td>не меньше 1000 (по умолчанию оно обычно равно 32767; без необходимости менять его не следует)</td></tr></tbody></table></div></div><br class="table-break" /><p><span class="productname">PostgreSQL</span> запрашивает небольшой блок разделяемой памяти System V (обычно 48 байт на 64-битной платформе) для каждой копии сервера. В большинстве современных операционных систем такой объём выделяется без проблем. Однако если запускать много копий сервера или явно настроить сервер для использования больших объёмов разделяемой памяти System V (см. <a class="xref" href="runtime-config-resource.html#GUC-SHARED-MEMORY-TYPE">shared_memory_type</a> и <a class="xref" href="runtime-config-resource.html#GUC-DYNAMIC-SHARED-MEMORY-TYPE">dynamic_shared_memory_type</a>), может понадобиться увеличить значение <code class="varname">SHMALL</code>, задающее общий объём разделяемой памяти System V, доступный для всей системы. Заметьте, что <code class="varname">SHMALL</code> во многих системах задаётся в страницах, а не в байтах.</p><p>Менее вероятны проблемы с минимальным размером сегментов разделяемой памяти (<code class="varname">SHMMIN</code>), который для <span class="productname">PostgreSQL</span> не должен превышать примерно 32 байт (обычно это всего 1 байт). Максимальное число сегментов для всей системы (<code class="varname">SHMMNI</code>) или для одного процесса (<code class="varname">SHMSEG</code>) тоже обычно не влияет на работоспособность сервера, если только это число не равно нулю.</p><p>Когда <span class="productname">PostgreSQL</span> использует семафоры System V, он занимает по одному семафору на одно разрешённое подключение (<a class="xref" href="runtime-config-connection.html#GUC-MAX-CONNECTIONS">max_connections</a>), на разрешённый рабочий процесс автоочистки (<a class="xref" href="runtime-config-autovacuum.html#GUC-AUTOVACUUM-MAX-WORKERS">autovacuum_max_workers</a>) и фоновый процесс (<a class="xref" href="runtime-config-resource.html#GUC-MAX-WORKER-PROCESSES">max_worker_processes</a>), в наборах по 16. В каждом таком наборе есть также 17-ый семафор, содержащий <span class="quote">«<span class="quote">магическое число</span>»</span>, позволяющий обнаруживать коллизии с наборами семафоров других приложений. Максимальное число семафоров в системе задаётся параметром <code class="varname">SEMMNS</code>, который, следовательно, должен быть равен как минимум сумме <code class="varname">max_connections</code>, <code class="varname">autovacuum_max_workers</code>, <code class="varname">max_wal_senders</code> и <code class="varname">max_worker_processes</code>, плюс один дополнительный на каждые 16 семафоров подключений и рабочих процессов (см. формулу в <a class="xref" href="kernel-resources.html#SYSVIPC-PARAMETERS" title="Таблица 19.1. Параметры IPC в стиле System V">Таблице 19.1</a>). Параметр <code class="varname">SEMMNI</code> определяет максимальное число наборов семафоров, которые могут существовать в системе в один момент времени. Таким образом, его значение должно быть не меньше чем <code class="literal">ceil((max_connections + autovacuum_max_workers + max_wal_senders + max_worker_processes + 5) / 16)</code>. В качестве временного решения проблем, которые вызываются этими ограничениями, но обычно сопровождаются некорректными сообщениями функции <code class="function">semget</code>, например, <span class="quote">«<span class="quote">No space left on device</span>»</span> (На устройстве не осталось места) можно уменьшить число разрешённых соединений.</p><p>В некоторых случаях может потребоваться увеличить <code class="varname">SEMMAP</code> как минимум до уровня <code class="varname">SEMMNS</code>. Если в системе есть такой параметр (а во многих системах его нет), он определяет размер карты ресурсов семафоров, в которой выделяется запись для каждого непрерывного блока семафоров. Когда набор семафоров освобождается, эта запись либо добавляется к существующей соседней записи, либо регистрируется как новая запись в карте. Если карта переполняется, освобождаемые семафоры теряются (до перезагрузки). Таким образом, фрагментация пространства семафоров может со временем привести к уменьшению числа доступных семафоров.</p><p>Другие параметры, связанные с <span class="quote">«<span class="quote">аннулированием операций</span>»</span> с семафорами, например, <code class="varname">SEMMNU</code> и <code class="varname">SEMUME</code>, на работу <span class="productname">PostgreSQL</span> не влияют.</p><p>При использовании семафоров POSIX требуемое их количество не отличается от количества для System V, то есть по одному семафору на разрешённое подключение (<a class="xref" href="runtime-config-connection.html#GUC-MAX-CONNECTIONS">max_connections</a>), на разрешённый рабочий процесс автоочистки (<a class="xref" href="runtime-config-autovacuum.html#GUC-AUTOVACUUM-MAX-WORKERS">autovacuum_max_workers</a>) и фоновый процесс (<a class="xref" href="runtime-config-resource.html#GUC-MAX-WORKER-PROCESSES">max_worker_processes</a>). На платформах, где предпочитается этот вариант, отсутствует определённый лимит ядра на количество семафоров POSIX.</p><div class="variablelist"><dl class="variablelist"><dt><span class="term"><span class="systemitem">AIX</span>
      <a id="id-1.6.6.7.3.14.1.1.2" class="indexterm"></a>
      </span></dt><dd><p>Для таких параметров, как <code class="varname">SHMMAX</code>, никакая дополнительная настройка не должна требоваться, так как система, похоже, позволяет использовать всю память в качестве разделяемой. Подобная конфигурация используется обычно и для других баз данных, например, для <span class="application">DB/2</span>.</p><p>Однако может понадобиться изменить глобальные параметры <code class="command">ulimit</code> в <code class="filename">/etc/security/limits</code>, так как стандартные жёсткие ограничения на размер (<code class="varname">fsize</code>) и количество файлов (<code class="varname">nofiles</code>) могут быть недостаточно большими.</p></dd><dt><span class="term"><span class="systemitem">FreeBSD</span>
      <a id="id-1.6.6.7.3.14.2.1.2" class="indexterm"></a>
      </span></dt><dd><p>Параметры разделяемой памяти по умолчанию вполне приемлемы, если вы не выберете в <code class="literal">shared_memory_type</code> вариант <code class="literal">sysv</code>. Семафоры System V на этой платформе не используются.</p><p>Значения параметров IPC по умолчанию можно изменить, используя возможности <code class="command">sysctl</code> или <code class="command">loader</code>. С помощью <code class="command">sysctl</code> можно задать следующие параметры: </p><pre class="screen">
<code class="prompt">#</code> <strong class="userinput"><code>sysctl kern.ipc.shmall=32768</code></strong>
<code class="prompt">#</code> <strong class="userinput"><code>sysctl kern.ipc.shmmax=134217728</code></strong>
</pre><p> Чтобы эти изменения сохранялись после перезагрузки, измените <code class="filename">/etc/sysctl.conf</code>.</p><p>Если вы выбрали в <code class="literal">shared_memory_type</code> вариант <code class="literal">sysv</code>, возможно, вы захотите настроить ядро так, чтобы разделяемая память System V всегда находилась в ОЗУ и никогда не выгружалась в пространство подкачки. Это можно сделать, установив с помощью <code class="command">sysctl</code> параметр <code class="literal">kern.ipc.shm_use_phys</code>.</p><p>Если вы запускаете сервер в «камере» FreeBSD, установите для параметра <code class="literal">sysvshm</code> значение <code class="literal">new</code>, чтобы у сервера было собственное отдельное пространство имён разделяемой памяти System V. (До версии 11.0 во FreeBSD требовалось разрешать общий доступ из камер к пространству имён IPC ведущего узла и принимать меры для недопущения конфликтов.)</p></dd><dt><span class="term"><span class="systemitem">NetBSD</span>
      <a id="id-1.6.6.7.3.14.3.1.2" class="indexterm"></a>
      </span></dt><dd><p>Параметры разделяемой памяти по умолчанию вполне приемлемы, если вы не выберете в <code class="literal">shared_memory_type</code> вариант <code class="literal">sysv</code>. Обычно имеет смысл увеличить <code class="literal">kern.ipc.semmni</code> и <code class="literal">kern.ipc.semmns</code>, так как их значения по умолчанию в <span class="systemitem">NetBSD</span> слишком малы.</p><p>Параметры IPC можно изменить, воспользовавшись командой <code class="command">sysctl</code>, например: </p><pre class="screen">
<code class="prompt">$</code> <strong class="userinput"><code>sysctl -w kern.ipc.semmni=100</code></strong>
</pre><p> Чтобы эти параметры сохранялись после перезагрузки, измените <code class="filename">/etc/sysctl.conf</code>.</p><p>Если вы выбрали в <code class="literal">shared_memory_type</code> вариант <code class="literal">sysv</code>, возможно, вы захотите настроить ядро так, чтобы разделяемая память System V всегда находилась в ОЗУ и никогда не выгружалась в пространство подкачки. Это можно сделать, установив с помощью <code class="command">sysctl</code> параметр <code class="literal">kern.ipc.shm_use_phys</code>.</p></dd><dt><span class="term"><span class="systemitem">OpenBSD</span>
      <a id="id-1.6.6.7.3.14.4.1.2" class="indexterm"></a>
      </span></dt><dd><p>Параметры разделяемой памяти по умолчанию вполне приемлемы, если вы не выберете в <code class="literal">shared_memory_type</code> вариант <code class="literal">sysv</code> Обычно имеет смысл увеличить <code class="literal">kern.seminfo.semmni</code> и <code class="literal">kern.seminfo.semmns</code>, так как их значения по умолчанию в <span class="systemitem">OpenBSD</span> слишком малы.</p><p>Параметры IPC можно изменить, воспользовавшись командой <code class="command">sysctl</code>, например: </p><pre class="screen">
<code class="prompt">$</code> <strong class="userinput"><code>sysctl kern.seminfo.semmni=100</code></strong>
</pre><p> Чтобы эти параметры сохранялись после перезагрузки, измените <code class="filename">/etc/sysctl.conf</code>.</p></dd><dt><span class="term"><span class="systemitem">Linux</span>
      <a id="id-1.6.6.7.3.14.5.1.2" class="indexterm"></a>
      </span></dt><dd><p>Параметры разделяемой памяти по умолчанию вполне приемлемы, если вы не выберете в <code class="literal">shared_memory_type</code> вариант <code class="literal">sysv</code>. И даже в этом случае их потребуется увеличить только для старых ядер, в которых эти параметры по умолчанию имеют маленькие значения. Семафоры System V на этой платформе не используются.</p><p>Параметры разделяемой памяти можно изменить, воспользовавшись командой <code class="command">sysctl</code>. Например, так можно выделить 16 ГБ: </p><pre class="screen">
<code class="prompt">$</code> <strong class="userinput"><code>sysctl -w kernel.shmmax=17179869184</code></strong>
<code class="prompt">$</code> <strong class="userinput"><code>sysctl -w kernel.shmall=4194304</code></strong>
</pre><p> Чтобы сохранить эти изменения после перезагрузки, воспользуйтесь файлом <code class="filename">/etc/sysctl.conf</code>.</p></dd><dt><span class="term"><span class="systemitem">macOS</span>
      <a id="id-1.6.6.7.3.14.6.1.2" class="indexterm"></a>
      </span></dt><dd><p>Параметры разделяемой памяти и семафоров по умолчанию вполне приемлемы, если вы не выберете в <code class="literal">shared_memory_type</code> вариант <code class="literal">sysv</code>.</p><p>Для настройки разделяемой памяти в macOS рекомендуется создать файл <code class="filename">/etc/sysctl.conf</code> и записать в него присваивания переменных следующим образом: </p><pre class="programlisting">kern.sysv.shmmax=4194304
kern.sysv.shmmin=1
kern.sysv.shmmni=32
kern.sysv.shmseg=8
kern.sysv.shmall=1024</pre><p> Заметьте, что в некоторых версиях macOS, <span class="emphasis"><em>все пять</em></span> параметров разделяемой памяти должны быть установлены в <code class="filename">/etc/sysctl.conf</code>, иначе их значения будут проигнорированы.</p><p>Значение <code class="varname">SHMMAX</code> должно быть кратно 4096.</p><p><code class="varname">SHMALL</code> на этой платформе измеряется в страницах (по 4 КБ).</p><p>Все параметры, кроме <code class="varname">SHMMNI</code> можно изменить «на лету», воспользовавшись командой <span class="application">sysctl</span>. Но тем не менее лучше задавать выбранные вами значения в <code class="filename">/etc/sysctl.conf</code>, чтобы они сохранялись после перезагрузки.</p></dd><dt><span class="term"><span class="systemitem">Solaris</span><br /></span><span class="term"><span class="systemitem">illumos</span></span></dt><dd><p>Параметры разделяемой памяти по умолчанию вполне приемлемы для большинства применений <span class="productname">PostgreSQL</span>. По умолчанию Solaris устанавливает в <code class="varname">SHMMAX</code> четверть объёма <acronym class="acronym">ОЗУ</acronym>. Чтобы выбрать другое значение, задайте соответствующий параметр проекта, связанного с пользователем <code class="literal">postgres</code>. Например, выполните от имени <code class="literal">root</code> такую команду: </p><pre class="programlisting">projadd -c "PostgreSQL DB User" -K "project.max-shm-memory=(privileged,8GB,deny)" -U postgres -G postgres user.postgres</pre><p>Эта команда создаёт проект <code class="literal">user.postgres</code> и устанавливает максимальный объём разделяемой памяти для пользователя <code class="literal">postgres</code> равным 8 ГБ. Это изменение вступает в силу при следующем входе этого пользователя или при перезапуске <span class="productname">PostgreSQL</span> (не перезагрузке конфигурации). При этом подразумевается, что <span class="productname">PostgreSQL</span> выполняется пользователем <code class="literal">postgres</code> в группе <code class="literal">postgres</code>. Перезагружать систему после этой команды не нужно.</p><p>Для серверов баз данных, рассчитанных на большое количество подключений, рекомендуется также изменить следующие параметры: </p><pre class="programlisting">project.max-shm-ids=(priv,32768,deny)
project.max-sem-ids=(priv,4096,deny)
project.max-msg-ids=(priv,4096,deny)</pre><p>Кроме того, если <span class="productname">PostgreSQL</span> у вас выполняется внутри зоны, может понадобиться также увеличить лимиты на использование ресурсов зоны. Получить дополнительную информацию о <code class="literal">проектах</code> и команде <code class="command">prctl</code> можно в <em class="citetitle">Руководстве системного администратора</em> (System Administrator's Guide), «Главе 2: Проекты и задачи» (Chapter2: Projects and Tasks).</p></dd></dl></div></div><div class="sect2" id="SYSTEMD-REMOVEIPC"><div class="titlepage"><div><div><h3 class="title">19.4.2. RemoveIPC в systemd <a href="#SYSTEMD-REMOVEIPC" class="id_link">#</a></h3></div></div></div><a id="id-1.6.6.7.4.2" class="indexterm"></a><p>Если используется <span class="productname">systemd</span>, необходимо позаботиться о том, чтобы ресурсы IPC (включая разделяемую память) не освобождались преждевременно операционной системой. Это особенно актуально при сборке и установке PostgreSQL из исходного кода. Пользователей дистрибутивных пакетов PostgreSQL это касается в меньшей степени, так как пользователь <code class="literal">postgres</code> обычно создаётся как системный пользователь.</p><p>Параметр <code class="literal">RemoveIPC</code> в <code class="filename">logind.conf</code> определяет, должны ли объекты IPC удаляться при полном выходе пользователя из системы. На системных пользователей это не распространяется. Этот параметр по умолчанию включён в стандартной сборке <span class="productname">systemd</span>, но в некоторых дистрибутивах операционных систем он по умолчанию отключён.</p><p>Обычно негативный эффект включения этого параметра проявляется в том, что объекты разделяемой памяти, используемые для параллельного выполнения запросов, удаляются без видимых причин, что приводит к появлению ошибок и предупреждений при попытке открыть и удалить их, например: </p><pre class="screen">
WARNING:  could not remove shared memory segment "/PostgreSQL.1450751626": No such file or directory
</pre><p> (ПРЕДУПРЕЖДЕНИЕ: ошибка при удалении сегмента разделяемой памяти "/PostgreSQL.1450751626": Нет такого файла или каталога) Различные типы объектов IPC (разделяемая память/семафоры, System V/POSIX) обрабатываются в <span class="productname">systemd</span> несколько по-разному, поэтому могут наблюдаться ситуации, когда некоторые ресурсы IPC не удаляются так, как другие. Однако полагаться на эти тонкие различия не рекомендуется.</p><p>Событие <span class="quote">«<span class="quote">выхода пользователя из системы</span>»</span> может произойти при выполнении задачи обслуживания или если администратор войдёт под именем <code class="literal">postgres</code>, а затем выйдет, либо случится что-то подобное, так что предотвратить это довольно сложно.</p><p>Какой пользователь является <span class="quote">«<span class="quote">системным</span>»</span>, определяется во время компиляции <span class="productname">systemd</span>, исходя из значения <code class="symbol">SYS_UID_MAX</code> в <code class="filename">/etc/login.defs</code>.</p><p>Скрипт упаковывания и развёртывания сервера должен предусмотрительно создавать пользователя <code class="literal">postgres</code> как системного пользователя, используя команды <code class="literal">useradd -r</code>, <code class="literal">adduser --system</code> или равнозначные.</p><p>Если же учётная запись пользователя была создана некорректно и изменить её невозможно, рекомендуется задать </p><pre class="programlisting">RemoveIPC=no</pre><p> в <code class="filename">/etc/systemd/logind.conf</code> или другом подходящем файле конфигурации.</p><div class="caution"><h3 class="title">Внимание</h3><p>Необходимо предпринять минимум одно из этих двух действий, иначе сервер PostgreSQL будет очень нестабильным.</p></div></div><div class="sect2" id="KERNEL-RESOURCES-LIMITS"><div class="titlepage"><div><div><h3 class="title">19.4.3. Ограничения ресурсов <a href="#KERNEL-RESOURCES-LIMITS" class="id_link">#</a></h3></div></div></div><p>В Unix-подобных операционных системах существуют различные типы ограничений ресурсов, которые могут влиять на работу сервера <span class="productname">PostgreSQL</span>. Особенно важны ограничения на число процессов для пользователя, число открытых файлов и объём памяти для каждого процесса. Каждое из этих ограничений имеет <span class="quote">«<span class="quote">жёсткий</span>»</span> и <span class="quote">«<span class="quote">мягкий</span>»</span> предел. Мягкий предел действительно ограничивает использование ресурса, но пользователь может увеличить его значение до жёсткого предела. Изменить жёсткий предел может только пользователь root. За изменение этих параметров отвечает системный вызов <code class="function">setrlimit</code>. Управлять этими ресурсами в командной строке позволяет встроенная команда <code class="command">ulimit</code> (в оболочках Bourne) и <code class="command">limit</code> (<span class="application">csh</span>). В системах семейства BSD различными ограничениями ресурсов, устанавливаемыми при входе пользователя, управляет файл <code class="filename">/etc/login.conf</code>. За подробностями обратитесь к документации операционной системы. Для <span class="productname">PostgreSQL</span> интерес представляют параметры <code class="varname">maxproc</code>, <code class="varname">openfiles</code> и <code class="varname">datasize</code>. Они могут задаваться, например так: </p><pre class="programlisting">default:\
...
        :datasize-cur=256M:\
        :maxproc-cur=256:\
        :openfiles-cur=256:\
...</pre><p> (Здесь <code class="literal">-cur</code> обозначает мягкий предел. Чтобы задать жёсткий предел, нужно заменить это окончание на <code class="literal">-max</code>.)</p><p>Ядро также может устанавливать общесистемные ограничения на использование некоторых ресурсов. </p><div class="itemizedlist"><ul class="itemizedlist" style="list-style-type: disc; "><li class="listitem"><p>В <span class="productname">Linux</span> максимальное число открытых файлов, которое поддерживает ядро, определяется параметром ядра <code class="varname">fs.file-max</code>. Изменить этот предел можно, воспользовавшись командой <code class="literal">sysctl -w fs.file-max=<em class="replaceable"><code>N</code></em></code>. Чтобы эти изменения сохранялись после перезагрузки, следует добавить присваивание в файл <code class="filename">/etc/sysctl.conf</code>. Максимальное число файлов для одного процесса задаётся при компиляции ядра; за дополнительными сведения обратитесь к <code class="filename">/usr/src/linux/Documentation/proc.txt</code>.</p></li></ul></div><p>Сервер <span class="productname">PostgreSQL</span> использует для обслуживания каждого подключения отдельный процесс, так что возможное число процессов должно быть не меньше числа разрешённых соединений плюс число процессов, требуемых для остальной системы. Это обычно не проблема, но когда в одной системе работает множество серверов, предел может быть достигнут.</p><p>В качестве максимального числа открытых файлов по умолчанию обычно выбираются <span class="quote">«<span class="quote">социально-ориентированные</span>»</span> значения, позволяющие использовать одну систему нескольким пользователям так, чтобы ни один из них не потреблял слишком много системных ресурсов. Если вы запускаете в системе несколько серверов, это должно вполне устраивать, но на выделенных машинах может возникнуть желание увеличить этот предел.</p><p>С другой стороны, некоторые системы позволяют отдельным процессам открывать очень много файлов и если это делают сразу несколько процессов, они могут легко исчерпать общесистемный предел. Если вы столкнётесь с такой ситуацией, но не захотите менять общесистемное ограничение, вы можете ограничить использование открытых файлов сервером <span class="productname">PostgreSQL</span>, установив параметр конфигурации <a class="xref" href="runtime-config-resource.html#GUC-MAX-FILES-PER-PROCESS">max_files_per_process</a>.</p><p>Ещё одно ограничение в ядре, с которым можно столкнуться, когда устанавливается большое количество клиентских подключений, — максимальная длина очереди подключений к сокету. Если количество запросов на подключение за короткий промежуток времени превышает этот максимум, некоторые из них будут отклонены до того, как сервер <span class="productname">PostgreSQL</span> сможет их обработать, при этом клиенты получат неинформативное сообщение об ошибке подключения типа <span class="quote">«<span class="quote">Resource temporarily unavailable</span>»</span> (Ресурс временно недоступен) или <span class="quote">«<span class="quote">Connection refused</span>»</span> (Не удалось подключиться). Предел длины очереди на многих платформах по умолчанию составляет 128. Чтобы увеличить его, настройте соответствующий параметр ядра через <span class="application">sysctl</span> и перезапустите сервер <span class="productname">PostgreSQL</span>. Этот параметр называется <code class="varname">net.core.somaxconn</code> в Linux, <code class="varname">kern.ipc.soacceptqueue</code> в последних версиях FreeBSD и <code class="varname">kern.ipc.somaxconn</code> в macOS и на других платформах BSD.</p></div><div class="sect2" id="LINUX-MEMORY-OVERCOMMIT"><div class="titlepage"><div><div><h3 class="title">19.4.4. Чрезмерное выделение памяти в Linux <a href="#LINUX-MEMORY-OVERCOMMIT" class="id_link">#</a></h3></div></div></div><a id="id-1.6.6.7.6.2" class="indexterm"></a><a id="id-1.6.6.7.6.3" class="indexterm"></a><a id="id-1.6.6.7.6.4" class="indexterm"></a><p>В Linux механизм виртуальной памяти по умолчанию работает не оптимально для <span class="productname">PostgreSQL</span>. Вследствие того, что ядро выделяет память в чрезмерном объёме, оно может уничтожить главный управляющий процесс <span class="productname">PostgreSQL</span> (postmaster), если при выделении памяти процессу <span class="productname">PostgreSQL</span> или другому процессу виртуальная память будет исчерпана.</p><p>Когда это происходит, вы можете получить примерно такое сообщение ядра (где именно искать это сообщение, можно узнать в документации вашей системы): </p><pre class="programlisting">Out of Memory: Killed process 12345 (postgres).</pre><p> Это сообщение говорит о том, что процесс <code class="filename">postgres</code> был уничтожен из-за нехватки памяти. Хотя существующие подключения к базе данных будут работать по-прежнему, новые подключения приниматься не будут. Чтобы восстановить работу сервера, <span class="productname">PostgreSQL</span> придётся перезапустить.</p><p>Один из способов обойти эту проблему — запускать <span class="productname">PostgreSQL</span> на компьютере, где никакие другие процессы не займут всю память. Если физической памяти недостаточно, решить проблему также можно, увеличив объём пространства подкачки, так как уничтожение процессов при нехватке памяти происходит только когда заканчивается и физическая память, и место в пространстве подкачки.</p><p>Если памяти не хватает по вине самого <span class="productname">PostgreSQL</span>, эту проблему можно решить, изменив конфигурацию сервера. В некоторых случаях может помочь уменьшение конфигурационных параметров, связанных с памятью, а именно <a class="link" href="runtime-config-resource.html#GUC-SHARED-BUFFERS"><code class="varname">shared_buffers</code></a>, <a class="link" href="runtime-config-resource.html#GUC-WORK-MEM"><code class="varname">work_mem</code></a> и <a class="link" href="runtime-config-resource.html#GUC-HASH-MEM-MULTIPLIER"><code class="varname">hash_mem_multiplier</code></a>. В других случаях проблема может возникать, потому что разрешено слишком много подключений к самому серверу баз данных. Чаще всего в такой ситуации стоит уменьшить число подключений <a class="link" href="runtime-config-connection.html#GUC-MAX-CONNECTIONS"><code class="varname">max_connections</code></a> и организовать внешний пул соединений.</p><p><span class="quote">«<span class="quote">Чрезмерное выделение</span>»</span> памяти можно предотвратить, изменив поведение ядра. Хотя при этом <a class="ulink" href="https://lwn.net/Articles/104179/" target="_top">OOM killer</a> (уничтожение процессов при нехватке памяти) всё равно может вызываться, вероятность такого уничтожения значительно уменьшается, а значит поведение системы становится более стабильным. Для этого нужно включить режим строгого выделения памяти, воспользовавшись <code class="command">sysctl</code>: </p><pre class="programlisting">sysctl -w vm.overcommit_memory=2</pre><p> либо поместив соответствующую запись в <code class="filename">/etc/sysctl.conf</code>. Возможно, вы также захотите изменить связанный параметр <code class="varname">vm.overcommit_ratio</code>. За подробностями обратитесь к документации ядра <a class="ulink" href="https://www.kernel.org/doc/Documentation/vm/overcommit-accounting" target="_top">https://www.kernel.org/doc/Documentation/vm/overcommit-accounting</a>.</p><p>Другой подход, который можно применить (возможно, вместе с изменением <code class="varname">vm.overcommit_memory</code>), заключается в исключении процесса postmaster из числа возможных жертв при нехватке памяти. Для этого нужно задать для свойства <em class="firstterm">поправка очков OOM</em> этого процесса значение <code class="literal">-1000</code>. Проще всего это можно сделать, выполнив </p><pre class="programlisting">echo -1000 &gt; /proc/self/oom_score_adj</pre><p> в скрипте запуска <span class="productname">PostgreSQL</span> непосредственно перед тем, как запускать <code class="filename">postgres</code>. Заметьте, что делать это надо под именем root, иначе ничего не изменится; поэтому проще всего вставить эту команду в стартовый скрипт, принадлежащий пользователю root. Если вы делаете это, вы также должны установить в данном скрипте эти переменные окружения перед запуском <code class="filename">postgres</code>: </p><pre class="programlisting">export PG_OOM_ADJUST_FILE=/proc/self/oom_score_adj
export PG_OOM_ADJUST_VALUE=0</pre><p> С такими параметрами дочерние процессы главного будут запускаться с обычной, нулевой поправкой очков OOM, так что при необходимости механизм OOM сможет уничтожать их. Вы можете задать и другое значение для <code class="envar">PG_OOM_ADJUST_VALUE</code>, если хотите, чтобы дочерние процессы исполнялись с другой поправкой OOM. (<code class="envar">PG_OOM_ADJUST_VALUE</code> также можно опустить, в этом случае подразумевается нулевое значение.) Если вы не установите <code class="envar">PG_OOM_ADJUST_FILE</code>, дочерние процессы будут работать с той же поправкой очков OOM, которая задана для главного процесса, что неразумно, так всё это делается как раз для того, чтобы главный процесс оказался на особом положении.</p></div><div class="sect2" id="LINUX-HUGE-PAGES"><div class="titlepage"><div><div><h3 class="title">19.4.5. Огромные страницы в Linux <a href="#LINUX-HUGE-PAGES" class="id_link">#</a></h3></div></div></div><p>Использование огромных страниц (huge pages) снижает накладные расходы при работе с большими непрерывными блоками памяти, что характерно для <span class="productname">PostgreSQL</span>, особенно при большом объёме <a class="xref" href="runtime-config-resource.html#GUC-SHARED-BUFFERS">shared_buffers</a>. Чтобы такие страницы можно было задействовать в <span class="productname">PostgreSQL</span>, ядро должно быть собрано с параметрами <code class="varname">CONFIG_HUGETLBFS=y</code> и <code class="varname">CONFIG_HUGETLB_PAGE=y</code>. Также вам понадобится настроить ОС, чтобы она могла выделить достаточное количество огромных страниц нужного размера. Чтобы определить требуемое количество огромных страниц, узнайте значение параметра <a class="xref" href="runtime-config-preset.html#GUC-SHARED-MEMORY-SIZE-IN-HUGE-PAGES">shared_memory_size_in_huge_pages</a>, воспользовавшись командой <code class="command">postgres</code>. Обратите внимание, что узнать значение этого вычисляемого параметра можно только при остановленном сервере. Например, вы можете получить: </p><pre class="programlisting">$ <strong class="userinput"><code>postgres -D $PGDATA -C shared_memory_size_in_huge_pages</code></strong>
3170
$ <strong class="userinput"><code>grep ^Hugepagesize /proc/meminfo</code></strong>
Hugepagesize:       2048 kB
$ <strong class="userinput"><code>ls /sys/kernel/mm/hugepages</code></strong>
hugepages-1048576kB  hugepages-2048kB</pre><p> В этом примере размер по умолчанию составляет 2 МБ, но задав в параметре <a class="xref" href="runtime-config-resource.html#GUC-HUGE-PAGE-SIZE">huge_page_size</a> 2 МБ или 1 ГБ явным образом, вы получите в <code class="varname">shared_memory_size_in_huge_pages</code> пересчитанное количество страниц. В данном примере серверу потребуется <code class="literal">3170</code> огромных страниц, но можно запросить и больше, если огромные страницы будут использоваться и другими программами в этой системе. Выбранное значение можно задать так: </p><pre class="programlisting"># <strong class="userinput"><code>sysctl -w vm.nr_hugepages=3170</code></strong></pre><p> Не забудьте добавить этот параметр в <code class="filename">/etc/sysctl.conf</code>, чтобы он действовал и после перезагрузки. Если же размер огромных страниц отличается от подразумеваемого по умолчанию, их количество можно задать так: </p><pre class="programlisting"># <strong class="userinput"><code>echo 3170 &gt; /sys/kernel/mm/hugepages/hugepages-2048kB/nr_hugepages</code></strong></pre><p> Также можно задать эти параметры во время загрузки ОС, установив соответствующие параметры ядра, например <code class="literal">hugepagesz=2M hugepages=3170</code>.</p><p>Иногда ядро не может сразу выделить запрошенное количество огромных страниц из-за фрагментации, поэтому может потребоваться повторить эту команду или перезагрузить систему. (Немедленно после перезагрузки должен быть свободен больший объём памяти для преобразования в огромные страницы.) Чтобы проверить текущую ситуацию с размещением огромных страниц определённого размера, выполните: </p><pre class="programlisting">$ <strong class="userinput"><code>cat /sys/kernel/mm/hugepages/hugepages-2048kB/nr_hugepages</code></strong></pre><p>Также может потребоваться дать пользователю операционной системы, запускающему сервер БД, право использовать огромные страницы, установив его группу в <code class="varname">vm.hugetlb_shm_group</code> с помощью <span class="application">sysctl</span>, и/или разрешить блокировать память, выполнив <code class="command">ulimit -l</code>.</p><p>По умолчанию <span class="productname">PostgreSQL</span> пытается использовать огромные страницы стандартного размера, а в противном случае переходит к обычным страницам. Чтобы задействовать огромные страницы принудительно, можно установить для <a class="xref" href="runtime-config-resource.html#GUC-HUGE-PAGES">huge_pages</a> значение <code class="literal">on</code> в <code class="filename">postgresql.conf</code>. Заметьте, что с таким значением <span class="productname">PostgreSQL</span> не сможет запуститься, если не получит достаточного количества огромных страниц.</p><p>Более подробно о механизме огромных страниц в <span class="productname">Linux</span> можно узнать в документации ядра: <a class="ulink" href="https://www.kernel.org/doc/Documentation/vm/hugetlbpage.txt" target="_top">https://www.kernel.org/doc/Documentation/vm/hugetlbpage.txt</a>.</p></div></div><div class="navfooter"><hr /><table width="100%" summary="Navigation footer"><tr><td width="40%" align="left"><a accesskey="p" href="server-start.html" title="19.3. Запуск сервера баз данных">Пред.</a> </td><td width="20%" align="center"><a accesskey="u" href="runtime.html" title="Глава 19. Подготовка к работе и сопровождение сервера">Наверх</a></td><td width="40%" align="right"> <a accesskey="n" href="server-shutdown.html" title="19.5. Выключение сервера">След.</a></td></tr><tr><td width="40%" align="left" valign="top">19.3. Запуск сервера баз данных </td><td width="20%" align="center"><a accesskey="h" href="index.html" title="Документация к PostgreSQL 16.3">Начало</a></td><td width="40%" align="right" valign="top"> 19.5. Выключение сервера</td></tr></table></div></body></html>