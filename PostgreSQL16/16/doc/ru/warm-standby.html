<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html xmlns="http://www.w3.org/1999/xhtml"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8" /><title>27.2. Трансляция журналов на резервные серверы</title><link rel="stylesheet" type="text/css" href="stylesheet.css" /><link rev="made" href="pgsql-docs@lists.postgresql.org" /><meta name="generator" content="DocBook XSL Stylesheets Vsnapshot" /><link rel="prev" href="different-replication-solutions.html" title="27.1. Сравнение различных решений" /><link rel="next" href="warm-standby-failover.html" title="27.3. Отработка отказа" /></head><body id="docContent" class="container-fluid col-10"><div class="navheader"><table width="100%" summary="Navigation header"><tr><th colspan="5" align="center">27.2. Трансляция журналов на резервные серверы</th></tr><tr><td width="10%" align="left"><a accesskey="p" href="different-replication-solutions.html" title="27.1. Сравнение различных решений">Пред.</a> </td><td width="10%" align="left"><a accesskey="u" href="high-availability.html" title="Глава 27. Отказоустойчивость, балансировка нагрузки и репликация">Наверх</a></td><th width="60%" align="center">Глава 27. Отказоустойчивость, балансировка нагрузки и репликация</th><td width="10%" align="right"><a accesskey="h" href="index.html" title="Документация к PostgreSQL 16.3">Начало</a></td><td width="10%" align="right"> <a accesskey="n" href="warm-standby-failover.html" title="27.3. Отработка отказа">След.</a></td></tr></table><hr /></div><div class="sect1" id="WARM-STANDBY"><div class="titlepage"><div><div><h2 class="title" style="clear: both">27.2. Трансляция журналов на резервные серверы <a href="#WARM-STANDBY" class="id_link">#</a></h2></div></div></div><div class="toc"><dl class="toc"><dt><span class="sect2"><a href="warm-standby.html#STANDBY-PLANNING">27.2.1. Планирование</a></span></dt><dt><span class="sect2"><a href="warm-standby.html#STANDBY-SERVER-OPERATION">27.2.2. Работа резервного сервера</a></span></dt><dt><span class="sect2"><a href="warm-standby.html#PREPARING-PRIMARY-FOR-STANDBY">27.2.3. Подготовка главного сервера для работы с резервными</a></span></dt><dt><span class="sect2"><a href="warm-standby.html#STANDBY-SERVER-SETUP">27.2.4. Настройка резервного сервера</a></span></dt><dt><span class="sect2"><a href="warm-standby.html#STREAMING-REPLICATION">27.2.5. Потоковая репликация</a></span></dt><dt><span class="sect2"><a href="warm-standby.html#STREAMING-REPLICATION-SLOTS">27.2.6. Слоты репликации</a></span></dt><dt><span class="sect2"><a href="warm-standby.html#CASCADING-REPLICATION">27.2.7. Каскадная репликация</a></span></dt><dt><span class="sect2"><a href="warm-standby.html#SYNCHRONOUS-REPLICATION">27.2.8. Синхронная репликация</a></span></dt><dt><span class="sect2"><a href="warm-standby.html#CONTINUOUS-ARCHIVING-IN-STANDBY">27.2.9. Непрерывное архивирование на резервном сервере</a></span></dt></dl></div><p>Постоянная архивация может использоваться для создания кластерной конфигурации <em class="firstterm">высокой степени доступности</em> (HA) с одним или несколькими <em class="firstterm">резервными серверами</em>, способными заменить ведущий сервер в случае выхода его из строя. Такую реализацию отказоустойчивости часто называют <em class="firstterm">тёплый резерв</em> или <em class="firstterm">трансляция журналов</em>.</p><p>Ведущий и резервный серверы работают совместно для обеспечения этой возможности, при этом они связаны опосредованно. Ведущий сервер работает в режиме постоянной архивации изменений, в то время как каждый резервный сервер работает в режиме постоянного приёма архивных изменений, получая файлы WAL от ведущего. Для обеспечения этой возможности не требуется вносить изменения в таблицы БД, поэтому администрировать данное решение репликации проще, чем ряд других. Так же такая конфигурация относительно слабо влияет на производительность ведущего сервера.</p><p>Непосредственную передачу записей WAL с одного сервера БД на другой обычно называют трансляцией журналов (или доставкой журналов). <span class="productname">PostgreSQL</span> реализует трансляцию журналов на уровне файлов, передавая записи WAL по одному файлу (сегменту WAL) единовременно. Файлы WAL (размером 16 МБ) можно легко и эффективно передать на любое расстояние, будь то соседний сервер, другая система в местной сети или сервер на другом краю света. Требуемая пропускная способность при таком подходе определяется скоростью записи транзакций на ведущем сервере. Трансляция журналов на уровне записей более фрагментарная операция, при которой изменения WAL передаются последовательно через сетевое соединение (см. <a class="xref" href="warm-standby.html#STREAMING-REPLICATION" title="27.2.5. Потоковая репликация">Подраздел 27.2.5</a>).</p><p>Следует отметить, что трансляция журналов асинхронна, то есть записи WAL доставляются после завершения транзакции. В результате образуется окно, когда возможна потеря данных при отказе сервера: будут утеряны ещё не переданные транзакции. Размер этого окна при трансляции файлов журналов может быть ограничен параметром <code class="varname">archive_timeout</code>, который может принимать значение меньше нескольких секунд. Тем не менее подобные заниженные значения могут потребовать существенного увеличения пропускной способности, необходимой для трансляции файлов. При потоковой репликации (см. <a class="xref" href="warm-standby.html#STREAMING-REPLICATION" title="27.2.5. Потоковая репликация">Подраздел 27.2.5</a>) окно возможности потери данных гораздо меньше.</p><p>Скорость восстановления достаточно высока, обычно резервный сервер становится полностью доступным через мгновение после активации. В результате такое решение называется тёплым резервом, что обеспечивает отличную отказоустойчивость. Восстановление сервера из архивной копии базы и применение изменений обычно происходит существенно дольше. Поэтому такие действия обычно требуются при восстановлении после аварии, не для отказоустойчивости. Так же резервный сервер может обрабатывать читающие запросы. В этом случае он называется сервером <em class="firstterm">горячего резерва</em>. См. <a class="xref" href="hot-standby.html" title="27.4. Горячий резерв">Раздел 27.4</a> для подробной информации.</p><a id="id-1.6.14.16.7" class="indexterm"></a><a id="id-1.6.14.16.8" class="indexterm"></a><a id="id-1.6.14.16.9" class="indexterm"></a><a id="id-1.6.14.16.10" class="indexterm"></a><a id="id-1.6.14.16.11" class="indexterm"></a><a id="id-1.6.14.16.12" class="indexterm"></a><div class="sect2" id="STANDBY-PLANNING"><div class="titlepage"><div><div><h3 class="title">27.2.1. Планирование <a href="#STANDBY-PLANNING" class="id_link">#</a></h3></div></div></div><p>Обычно разумно подбирать ведущий и резервный серверы так, чтобы они были максимально похожи, как минимум с точки зрения базы данных. Тогда в частности, пути, связанные с табличными пространствами, могут передаваться без изменений. Таким образом, как на ведущем, так и на резервных серверах должны быть одинаковые пути монтирования для табличных пространств при использовании этой возможности БД. Учитывайте, что если <a class="xref" href="sql-createtablespace.html" title="CREATE TABLESPACE"><span class="refentrytitle">CREATE TABLESPACE</span></a> выполнена на ведущем сервере, новая точка монтирования для этой команды уже должна существовать на резервных серверах до её выполнения. Аппаратная часть не должна быть в точности одинаковой, но опыт показывает, что сопровождать идентичные системы легче, чем две различные на протяжении жизненного цикла приложения и системы. В любом случае архитектура оборудования должна быть одинаковой — например, трансляция журналов с 32-битной на 64-битную систему не будет работать.</p><p>В общем случае трансляция журналов между серверами с различными основными версиями <span class="productname">PostgreSQL</span> невозможна. Политика главной группы разработки PostgreSQL состоит в том, чтобы не вносить изменения в дисковые форматы при обновлениях корректирующей версии, таким образом, ведущий и резервный серверы, имеющие разные корректирующие версии, могут работать успешно. Тем не менее формально такая возможность не поддерживается, поэтому рекомендуется поддерживать одинаковую версию ведущего и резервных серверов, насколько это возможно. При обновлении корректирующей версии безопаснее будет в первую очередь обновить резервные серверы — новая корректирующая версия с большей вероятностью прочитает файл WAL предыдущей корректирующей версии, чем наоборот.</p></div><div class="sect2" id="STANDBY-SERVER-OPERATION"><div class="titlepage"><div><div><h3 class="title">27.2.2. Работа резервного сервера <a href="#STANDBY-SERVER-OPERATION" class="id_link">#</a></h3></div></div></div><p>Сервер переходит в режим ожидания, если в каталоге данных при запуске сервера есть файл <span id="FILE-STANDBY-SIGNAL"></span><code class="filename">standby.signal</code><a id="id-1.6.14.16.14.2.3" class="indexterm"></a>.</p><p>Сервер, работающий в режиме резервного, последовательно применяет файлы WAL, полученные от главного. Резервный сервер может читать файлы WAL из архива WAL (см. <a class="xref" href="runtime-config-wal.html#GUC-RESTORE-COMMAND">restore_command</a>) или напрямую с главного сервера по соединению TCP (потоковая репликация). Резервный сервер также будет пытаться восстановить любой файл WAL, найденный в кластере резервного в каталоге <code class="filename">pg_wal</code>. Это обычно происходит после перезапуска сервера, когда он применяет заново файлы WAL, полученные от главного сервера перед перезапуском. Но можно и вручную скопировать файлы в каталог <code class="filename">pg_wal</code>, чтобы применить их в любой момент времени.</p><p>В момент запуска резервный сервер начинает восстанавливать все доступные файлы WAL, размещённые в архивном каталоге, указанном в команде <code class="varname">restore_command</code>. По достижении конца доступных файлов WAL или при сбое команды <code class="varname">restore_command</code> сервер пытается восстановить все файлы WAL, доступные в каталоге <code class="filename">pg_wal</code>. Если это не удаётся и потоковая репликация настроена, резервный сервер пытается присоединиться к ведущему и начать закачивать поток WAL с последней подтверждённой записи, найденной в архиве или <code class="filename">pg_wal</code>. Если это действие закончилось неудачей, или потоковая репликация не настроена, или соединение позднее разорвалось, резервный сервер возвращается к шагу 1 и пытается восстановить файлы из архива вновь. Цикл обращения за файлами WAL к архиву, <code class="filename">pg_wal</code>, и через потоковую репликацию продолжается до остановки сервера или его повышения до ведущего.</p><p>Режим резерва завершается и сервер переключается в обычный рабочий режим при получении команды <code class="command">pg_ctl promote</code> или в результате вызова <code class="function">pg_promote()</code>. Перед переключением сервер восстановит все файлы WAL, непосредственно доступные из архива или <code class="filename">pg_wal</code>, но пытаться подключиться к главному серверу он больше не будет.</p></div><div class="sect2" id="PREPARING-PRIMARY-FOR-STANDBY"><div class="titlepage"><div><div><h3 class="title">27.2.3. Подготовка главного сервера для работы с резервными <a href="#PREPARING-PRIMARY-FOR-STANDBY" class="id_link">#</a></h3></div></div></div><p>Настройка постоянного архивирования на ведущем сервере в архивный каталог, доступный с резервного, описана в <a class="xref" href="continuous-archiving.html" title="26.3. Непрерывное архивирование и восстановление на момент времени (Point-in-Time Recovery, PITR)">Разделе 26.3</a>. Расположение архива должно быть доступно с резервного сервера даже при отключении главного, то есть его следует разместить на резервном или другом доверенном, но не на главном сервере.</p><p>При использовании потоковой репликации следует настроить режим аутентификации на ведущем сервере, чтобы разрешить соединения с резервных. Для этого создать роль и обеспечить подходящую запись в файле <code class="filename">pg_hba.conf</code> в разделе доступа к БД <code class="literal">replication</code>. Так же следует убедиться, что для параметра <code class="varname">max_wal_senders</code> задаётся достаточно большое значение в конфигурационном файле ведущего сервера. При использовании слотов для репликации также достаточно большое значение нужно задать для <code class="varname">max_replication_slots</code>.</p><p>Создание базовой резервной копии, необходимой для запуска резервного сервера, описано в <a class="xref" href="continuous-archiving.html#BACKUP-BASE-BACKUP" title="26.3.2. Создание базовой резервной копии">Подразделе 26.3.2</a>.</p></div><div class="sect2" id="STANDBY-SERVER-SETUP"><div class="titlepage"><div><div><h3 class="title">27.2.4. Настройка резервного сервера <a href="#STANDBY-SERVER-SETUP" class="id_link">#</a></h3></div></div></div><p>Для запуска резервного сервера нужно восстановить резервную копию, снятую с ведущего (см. <a class="xref" href="continuous-archiving.html#BACKUP-PITR-RECOVERY" title="26.3.4. Восстановление непрерывной архивной копии">Подраздел 26.3.4</a>). Затем нужно создать файл <a class="link" href="warm-standby.html#FILE-STANDBY-SIGNAL"><code class="filename">standby.signal</code></a><a id="id-1.6.14.16.16.2.3" class="indexterm"></a> в каталоге данных кластера резервного сервера. Задайте в <a class="xref" href="runtime-config-wal.html#GUC-RESTORE-COMMAND">restore_command</a> обычную команду копирования файлов из архива WAL. Если планируется несколько резервных серверов в целях отказоустойчивости, значением параметра <code class="varname">recovery_target_timeline</code> должно быть <code class="literal">latest</code> (значение по умолчанию), чтобы резервный сервер переходил на новую линию времени, образуемую при обработке отказа и переключении на другой сервер.</p><div class="note"><h3 class="title">Примечание</h3><p>Команда <a class="xref" href="runtime-config-wal.html#GUC-RESTORE-COMMAND">restore_command</a> должна немедленно завершиться при отсутствии файла; сервер повторит эту команду при необходимости.</p></div><p>При необходимости потоковой репликации задайте в <a class="xref" href="runtime-config-replication.html#GUC-PRIMARY-CONNINFO">primary_conninfo</a> параметры строки соединения для libpq, включая имя (или IP-адрес) сервера и всё, что требуется для подключения к ведущему серверу. Если ведущий требует пароль для аутентификации, пароль также должен быть указан в <a class="xref" href="runtime-config-replication.html#GUC-PRIMARY-CONNINFO">primary_conninfo</a>.</p><p>Если резервный сервер настраивается в целях отказоустойчивости, на нём следует настроить архивацию WAL, соединения и аутентификацию, как на ведущем сервере, потому что резервный сервер станет ведущим после отработки отказа.</p><p>При использовании архива WAL его размер может быть уменьшен с помощью команды, задаваемой в <a class="xref" href="runtime-config-wal.html#GUC-ARCHIVE-CLEANUP-COMMAND">archive_cleanup_command</a>, если она будет удалять файлы, ставшие ненужными для резервного сервера. Утилита <span class="application">pg_archivecleanup</span> разработана специально для использования в <code class="varname">archive_cleanup_command</code> при типичной конфигурации с одним резервным сервером (см. <a class="xref" href="pgarchivecleanup.html" title="pg_archivecleanup"><span class="refentrytitle"><span class="application">pg_archivecleanup</span></span></a>). Заметьте, что если архив используется в целях резервирования, необходимо сохранять все файлы, требующиеся для восстановления как минимум с последней базовой резервной копии, даже если они не нужны для резервного сервера.</p><p>Простой пример конфигурации: </p><pre class="programlisting">primary_conninfo = 'host=192.168.1.50 port=5432 user=foo password=foopass options=''-c wal_sender_timeout=5000'''
restore_command = 'cp /path/to/archive/%f %p'
archive_cleanup_command = 'pg_archivecleanup /path/to/archive %r'</pre><p>Можно поддерживать любое количество резервных серверов, но при применении потоковой репликации необходимо убедиться, что значение <code class="varname">max_wal_senders</code> на ведущем достаточно большое, чтобы все они могли подключиться одновременно.</p></div><div class="sect2" id="STREAMING-REPLICATION"><div class="titlepage"><div><div><h3 class="title">27.2.5. Потоковая репликация <a href="#STREAMING-REPLICATION" class="id_link">#</a></h3></div></div></div><a id="id-1.6.14.16.17.2" class="indexterm"></a><p>При потоковой репликации резервный сервер может работать с меньшей задержкой, чем при трансляции файлов. Резервный сервер подключается к ведущему, который передаёт поток записей WAL резервному в момент их добавления, не дожидаясь окончания заполнения файла WAL.</p><p>Потоковая репликация асинхронна по умолчанию (см. <a class="xref" href="warm-standby.html#SYNCHRONOUS-REPLICATION" title="27.2.8. Синхронная репликация">Подраздел 27.2.8</a>), то есть имеется небольшая задержка между подтверждением транзакции на ведущем сервере и появлением этих изменений на резервном. Тем не менее эта задержка гораздо меньше, чем при трансляции файлов журналов, обычно в пределах одной секунды, если резервный сервер достаточно мощный и справляется с нагрузкой. При потоковой репликации настраивать <code class="varname">archive_timeout</code> для уменьшения окна потенциальной потери данных не требуется.</p><p>При потоковой репликации без постоянной архивации на уровне файлов, сервер может избавиться от старых сегментов WAL до того, как резервный получит их. В этом случае резервный сервер потребует повторной инициализации из новой базовой резервной копии. Этого можно избежать, установив для <code class="varname">wal_keep_size</code> достаточно большое значение, при котором сегменты WAL будут защищены от ранней очистки, либо настроив слот репликации для резервного сервера. Если с резервного сервера доступен архив WAL, этого не требуется, так как резервный может всегда обратиться к архиву для восполнения пропущенных сегментов.</p><p>Чтобы настроить потоковую репликацию, сначала настройте резервный сервер в режиме передачи журналов в виде файлов, как описано в <a class="xref" href="warm-standby.html" title="27.2. Трансляция журналов на резервные серверы">Разделе 27.2</a>. Затем переключите его в режим потоковой репликации, установив в <code class="varname">primary_conninfo</code> строку подключения, указывающую на ведущий. Настройте <a class="xref" href="runtime-config-connection.html#GUC-LISTEN-ADDRESSES">listen_addresses</a> и параметры аутентификации (см. <code class="filename">pg_hba.conf</code>) на ведущем сервере таким образом, чтобы резервный смог подключиться к псевдобазе <code class="literal">replication</code> ведущего (см. <a class="xref" href="warm-standby.html#STREAMING-REPLICATION-AUTHENTICATION" title="27.2.5.1. Аутентификация">Подраздел 27.2.5.1</a>).</p><p>В системах, поддерживающих параметр сокета keepalive, подходящие значения <a class="xref" href="runtime-config-connection.html#GUC-TCP-KEEPALIVES-IDLE">tcp_keepalives_idle</a>, <a class="xref" href="runtime-config-connection.html#GUC-TCP-KEEPALIVES-INTERVAL">tcp_keepalives_interval</a> и <a class="xref" href="runtime-config-connection.html#GUC-TCP-KEEPALIVES-COUNT">tcp_keepalives_count</a> помогут ведущему вовремя заметить разрыв соединения.</p><p>Установите максимальное количество одновременных соединений с резервных серверов (см. описание <a class="xref" href="runtime-config-replication.html#GUC-MAX-WAL-SENDERS">max_wal_senders</a>).</p><p>При запуске резервного сервера с правильно установленным <code class="varname">primary_conninfo</code> резервный подключится к ведущему после воспроизведения всех файлов WAL, доступных из архива. При успешном установлении соединения можно увидеть <code class="literal">walreceiver</code> на резервном сервере и соответствующий процесс <code class="literal">walsender</code> на ведущем.</p><div class="sect3" id="STREAMING-REPLICATION-AUTHENTICATION"><div class="titlepage"><div><div><h4 class="title">27.2.5.1. Аутентификация <a href="#STREAMING-REPLICATION-AUTHENTICATION" class="id_link">#</a></h4></div></div></div><p>Право использования репликации очень важно ограничить так, чтобы только доверенные пользователи могли читать поток WAL, так как из него можно извлечь конфиденциальную информацию. Резервный сервер должен аутентифицироваться на главном от имени пользователя с правом <code class="literal">REPLICATION</code> или от имени суперпользователя. Настоятельно рекомендуется создавать выделенного пользователя с правами <code class="literal">REPLICATION</code> и <code class="literal">LOGIN</code> специально для репликации. Хотя право <code class="literal">REPLICATION</code> даёт очень широкие полномочия, оно не позволяет модифицировать данные в ведущей системе, тогда как с правом <code class="literal">SUPERUSER</code> это можно делать.</p><p>Список аутентификации клиентов для репликации содержится в <code class="filename">pg_hba.conf</code> в записях с установленным значением <code class="literal">replication</code> в поле <em class="replaceable"><code>database</code></em>. Например, если резервный сервер запущен на компьютере с IP-адресом <code class="literal">192.168.1.100</code> и учётная запись для репликации <code class="literal">foo</code>, администратор может добавить следующую строку в файл <code class="filename">pg_hba.conf</code> ведущего: </p><pre class="programlisting"># Разрешить пользователю "foo" с компьютера 192.168.1.100 подключаться к этому
# серверу в качестве партнёра репликации, если был передан правильный пароль.
#
# TYPE  DATABASE        USER            ADDRESS                 METHOD
host    replication     foo             192.168.1.100/32        md5</pre><p>Имя компьютера и номер порта для ведущего, имя подключающегося пользователя и пароль указываются в <a class="xref" href="runtime-config-replication.html#GUC-PRIMARY-CONNINFO">primary_conninfo</a>. Пароль также может быть задан в файле <code class="filename">~/.pgpass</code> на резервном сервере (в поле <em class="replaceable"><code>database</code></em> нужно указать <code class="literal">replication</code>). Например, если ведущий принимает подключения по IP-адресу <code class="literal">192.168.1.50</code>, через порт <code class="literal">5432</code>, пользователя для репликации <code class="literal">foo</code> с паролем <code class="literal">foopass</code>, администратор может добавить следующую строку в файл <code class="filename">postgresql.conf</code> на резервном сервере: </p><pre class="programlisting"># Резервный сервер подключается к ведущему, работающему на компьютере 192.168.1.50
# (порт 5432), от имени пользователя "foo" с паролем "foopass".
primary_conninfo = 'host=192.168.1.50 port=5432 user=foo password=foopass'</pre></div><div class="sect3" id="STREAMING-REPLICATION-MONITORING"><div class="titlepage"><div><div><h4 class="title">27.2.5.2. Наблюдение <a href="#STREAMING-REPLICATION-MONITORING" class="id_link">#</a></h4></div></div></div><p>Важным индикатором стабильности работы потоковой репликации является количество записей WAL, созданных на ведущем, но ещё не применённых на резервном сервере. Задержку можно подсчитать, сравнив текущую позиции записи WAL на ведущем с последней позицией WAL, полученной на резервном сервере. Эти позиции можно узнать, воспользовавшись функциями <code class="function">pg_current_wal_lsn</code> на ведущем и <code class="function">pg_last_wal_receive_lsn</code> на резервном, соответственно (за подробностями обратитесь к <a class="xref" href="functions-admin.html#FUNCTIONS-ADMIN-BACKUP-TABLE" title="Таблица 9.91. Функции управления резервным копированием">Таблице 9.91</a> и <a class="xref" href="functions-admin.html#FUNCTIONS-RECOVERY-INFO-TABLE" title="Таблица 9.92. Функции для получения информации о восстановлении">Таблице 9.92</a>). Последняя полученная позиция WAL на резервном сервере также выводится в состоянии процесса-приёмника WAL, которое показывает команда <code class="command">ps</code> (подробнее об этом в <a class="xref" href="monitoring-ps.html" title="28.1. Стандартные инструменты Unix">Разделе 28.1</a>).</p><p>Список процессов-передатчиков WAL можно получить через представление <a class="link" href="monitoring-stats.html#MONITORING-PG-STAT-REPLICATION-VIEW" title="28.2.4. pg_stat_replication"><code class="structname">pg_stat_replication</code></a>. Большая разница между <code class="function">pg_current_wal_lsn</code> и полем <code class="literal">sent_lsn</code> этого представления может указывать на то, что главный сервер работает с большой нагрузкой, тогда как разница между <code class="literal">sent_lsn</code> и <code class="function">pg_last_wal_receive_lsn</code> на резервном может быть признаком задержек в сети или большой нагрузки резервного сервера.</p><p>На сервере горячего резерва состояние процесса-приёмника WAL можно получить через представление <a class="link" href="monitoring-stats.html#MONITORING-PG-STAT-WAL-RECEIVER-VIEW" title="28.2.6. pg_stat_wal_receiver"><code class="structname">pg_stat_wal_receiver</code></a>. Большая разница между <code class="function">pg_last_wal_replay_lsn</code> и полем <code class="literal">flushed_lsn</code> свидетельствует о том, что WAL поступает быстрее, чем удаётся его воспроизвести.</p></div></div><div class="sect2" id="STREAMING-REPLICATION-SLOTS"><div class="titlepage"><div><div><h3 class="title">27.2.6. Слоты репликации <a href="#STREAMING-REPLICATION-SLOTS" class="id_link">#</a></h3></div></div></div><a id="id-1.6.14.16.18.2" class="indexterm"></a><p>Слоты репликации автоматически обеспечивают механизм сохранения сегментов WAL, пока они не будут получены всеми резервными и главный сервер не будет удалять строки, находящиеся в статусе <a class="link" href="hot-standby.html#HOT-STANDBY-CONFLICT" title="27.4.2. Обработка конфликтов запросов">recovery conflict</a> даже при отключении резервного.</p><p>Вместо использования слотов репликации для предотвращения удаления старых сегментов WAL можно применять <a class="xref" href="runtime-config-replication.html#GUC-WAL-KEEP-SIZE">wal_keep_size</a> или сохранять сегменты в архиве с помощью <a class="xref" href="runtime-config-wal.html#GUC-ARCHIVE-COMMAND">archive_command</a> или <a class="xref" href="runtime-config-wal.html#GUC-ARCHIVE-LIBRARY">archive_library</a>. Тем не менее эти методы часто приводят к тому, что хранится больше сегментов WAL, чем необходимо, в то время как для слотов репликации сохраняются только те сегменты, которые нужны. С другой стороны, для слотов репликации может потребоваться так много сегментов WAL, что они заполнят всё пространство, отведённое для <code class="literal">pg_wal</code>; объём файлов WAL, сохраняемых для слотов репликации, ограничивается параметром <a class="xref" href="runtime-config-replication.html#GUC-MAX-SLOT-WAL-KEEP-SIZE">max_slot_wal_keep_size</a>.</p><p>Подобным образом параметр <a class="xref" href="runtime-config-replication.html#GUC-HOT-STANDBY-FEEDBACK">hot_standby_feedback</a> сам по себе, без использования слота репликации, позволяет защитить востребованные строки от удаления при очистке, но не защищает в тот промежуток времени, когда резервный сервер не подключён. Слоты репликации решают эти проблемы.</p><div class="sect3" id="STREAMING-REPLICATION-SLOTS-MANIPULATION"><div class="titlepage"><div><div><h4 class="title">27.2.6.1. Запросы и действия слотов репликации <a href="#STREAMING-REPLICATION-SLOTS-MANIPULATION" class="id_link">#</a></h4></div></div></div><p>Каждый слот репликации обладает именем, состоящим из строчных букв, цифр и символов подчёркивания.</p><p>Имеющиеся слоты репликации и их статус можно просмотреть в представлении <a class="link" href="view-pg-replication-slots.html" title="54.19. pg_replication_slots"><code class="structname">pg_replication_slots</code></a>.</p><p>Слоты могут быть созданы и удалены как с помощью протокола потоковой репликации (см. <a class="xref" href="protocol-replication.html" title="55.4. Протокол потоковой репликации">Раздел 55.4</a>), так и посредством функций SQL (см. <a class="xref" href="functions-admin.html#FUNCTIONS-REPLICATION" title="9.27.6. Функции управления репликацией">Подраздел 9.27.6</a>).</p></div><div class="sect3" id="STREAMING-REPLICATION-SLOTS-CONFIG"><div class="titlepage"><div><div><h4 class="title">27.2.6.2. Пример конфигурации <a href="#STREAMING-REPLICATION-SLOTS-CONFIG" class="id_link">#</a></h4></div></div></div><p>Для создания слота репликации выполните: </p><pre class="programlisting">postgres=# SELECT * FROM pg_create_physical_replication_slot('node_a_slot');
  slot_name  | lsn
-------------+-----
 node_a_slot |

postgres=# SELECT slot_name, slot_type, active FROM pg_replication_slots;
  slot_name  | slot_type | active
-------------+-----------+--------
 node_a_slot | physical  | f
(1 row)</pre><p> Чтобы резервный сервер использовал этот слот, укажите его в параметре <code class="varname">primary_slot_name</code> в конфигурации этого сервера. Например: </p><pre class="programlisting">primary_conninfo = 'host=192.168.1.50 port=5432 user=foo password=foopass'
primary_slot_name = 'node_a_slot'</pre></div></div><div class="sect2" id="CASCADING-REPLICATION"><div class="titlepage"><div><div><h3 class="title">27.2.7. Каскадная репликация <a href="#CASCADING-REPLICATION" class="id_link">#</a></h3></div></div></div><a id="id-1.6.14.16.19.2" class="indexterm"></a><p>Свойство каскадной репликации позволяет резервному серверу принимать соединения репликации и потоки WAL от других резервных, выступающих посредниками. Это может быть полезно для уменьшения числа непосредственных подключений к главному серверу, а также для уменьшения накладных расходов при передаче данных в интрасети.</p><p>Резервный сервер, выступающий как получатель и отправитель, называется каскадным резервным сервером. Резервные серверы, стоящие ближе к главному, называются серверами верхнего уровня, а более отдалённые — серверами нижнего уровня. Каскадная репликация не накладывает ограничений на количество или организацию последующих уровней, а каждый резервный соединяется только с одним сервером вышестоящего уровня, который в конце концов соединяется с единственным главным/ведущим сервером.</p><p>Резервный сервер каскадной репликации не только получает записи WAL от главного, но так же восстанавливает их из архива. Таким образом, даже если соединение с сервером более высокого уровня разорвётся, потоковая репликация для последующих уровней будет продолжаться до исчерпания доступных записей WAL.</p><p>Каскадная репликация в текущей реализации асинхронна. Параметры синхронной репликации (см. <a class="xref" href="warm-standby.html#SYNCHRONOUS-REPLICATION" title="27.2.8. Синхронная репликация">Подраздел 27.2.8</a>) в настоящее время не оказывают влияние на каскадную репликацию.</p><p>Распространение обратной связи горячего резерва работает от нижестоящего уровня к вышестоящему уровню вне зависимости от способа организации связи.</p><p>Если вышестоящий резервный сервер будет преобразован в новый главный, нижестоящие серверы продолжат получать поток с нового главного при условии, что <code class="varname">recovery_target_timeline</code> имеет значение <code class="literal">latest</code> (по умолчанию).</p><p>Для использования каскадной репликации необходимо настроить резервный каскадный сервер на приём соединений репликации (то есть установить <a class="xref" href="runtime-config-replication.html#GUC-MAX-WAL-SENDERS">max_wal_senders</a> и <a class="xref" href="runtime-config-replication.html#GUC-HOT-STANDBY">hot_standby</a>, настроить <a class="link" href="auth-pg-hba-conf.html" title="21.1. Файл pg_hba.conf">host-based authentication</a>). Так же может быть необходимо настроить на нижестоящем резервном значение <code class="varname">primary_conninfo</code> на каскадный резервный сервер.</p></div><div class="sect2" id="SYNCHRONOUS-REPLICATION"><div class="titlepage"><div><div><h3 class="title">27.2.8. Синхронная репликация <a href="#SYNCHRONOUS-REPLICATION" class="id_link">#</a></h3></div></div></div><a id="id-1.6.14.16.20.2" class="indexterm"></a><p>По умолчанию в <span class="productname">PostgreSQL</span> потоковая репликация асинхронна. Если ведущий сервер выходит из строя, некоторые транзакции, которые были подтверждены, но не переданы на резервный, могут быть потеряны. Объём потерянных данных пропорционален задержке репликации на момент отработки отказа.</p><p>Синхронная репликация предоставляет возможность гарантировать, что все изменения, внесённые в транзакции, были переданы одному или нескольким синхронным резервным серверам. Это повышает стандартный уровень надёжности, гарантируемый при фиксации транзакции. Этот уровень защиты соответствует второму уровню безопасности репликации из теории вычислительной техники, или групповой безопасности первого уровня (безопасности групповой и уровня 1), когда выбран режим <code class="varname">synchronous_commit</code> <code class="literal">remote_write</code>.</p><p>При синхронной репликации каждая фиксация пишущей транзакции ожидает подтверждения того, что запись фиксации помещена в журнал предзаписи на диске на обоих серверах: ведущем и резервном. При таком варианте потеря данных может произойти только в случае одновременного выхода из строя ведущего и резервного серверов. Это обеспечивает более высокий уровень надёжности, при условии продуманного подхода системного администратора к вопросам размещения и управления этими серверами. Ожидание подтверждения увеличивает уверенность в том, что данные не будут потеряны во время сбоя сервера, но при этом увеличивает время отклика для обработки транзакции. Минимальное время ожидания равно времени передачи данных от ведущего к резервному и обратно.</p><p>Транзакции только для чтения и откат транзакции не требуют ожидания для ответа с резервного сервера. Промежуточные подтверждения не ожидают ответа от резервного сервера, только подтверждение верхнего уровня. Долгие операции вида загрузки данных или построения индекса не ожидают финального подтверждения. Но все двухфазные подтверждения требуют ожидания, включая подготовку и непосредственно подтверждение.</p><p>Синхронным резервным сервером может быть резервный сервер при физической репликации или подписчик при логической репликации. Это также может быть другой потребитель потока логической или физической репликации, способный отправлять в ответ требуемые сообщения. Помимо встроенных систем логической и физической репликации, к таким потребителям относятся специальные программы, <code class="command">pg_receivewal</code> и <code class="command">pg_recvlogical</code>, а также некоторые сторонние системы репликации и внешние программы. Подробнее об организации синхронной репликации с их использованием можно узнать в соответствующей документации.</p><div class="sect3" id="SYNCHRONOUS-REPLICATION-CONFIG"><div class="titlepage"><div><div><h4 class="title">27.2.8.1. Базовая настройка <a href="#SYNCHRONOUS-REPLICATION-CONFIG" class="id_link">#</a></h4></div></div></div><p>При настроенной потоковой репликации установка синхронной репликации требует только дополнительной настройки: необходимо выставить <a class="xref" href="runtime-config-replication.html#GUC-SYNCHRONOUS-STANDBY-NAMES">synchronous_standby_names</a> в непустое значение. Так же необходимо установить <code class="varname">synchronous_commit</code> в значение <code class="literal">on</code>, но так как это значение по умолчанию, обычно действий не требуется. (См. <a class="xref" href="runtime-config-wal.html#RUNTIME-CONFIG-WAL-SETTINGS" title="20.5.1. Параметры">Подраздел 20.5.1</a> и <a class="xref" href="runtime-config-replication.html#RUNTIME-CONFIG-REPLICATION-PRIMARY" title="20.6.2. Главный сервер">Подраздел 20.6.2</a>.) В такой конфигурации каждая транзакция будет ожидать подтверждение того, что на резервном сервере произошла запись транзакции в надёжное хранилище. Значение <code class="varname">synchronous_commit</code> может быть выставлено для отдельного пользователя, может быть прописано в файле конфигурации, для конкретного пользователя или БД или динамически изменено приложением для управления степенью надёжности на уровне отдельных транзакций.</p><p>После сохранения записи о фиксации транзакции на диске ведущего сервера эта запись WAL передаётся резервному серверу. Резервный сервер отвечает подтверждающим сообщением после сохранения каждого нового блока данных WAL на диске, если только <code class="varname">wal_receiver_status_interval</code> на нём не равен нулю. В случае, когда выбран режим <code class="varname">synchronous_commit</code> <code class="literal">remote_apply</code>, резервный сервер передаёт подтверждение после воспроизведения записи фиксации, когда транзакция становится видимой. Если резервный сервер выбран на роль синхронного резервного в соответствии со значением <code class="varname">synchronous_standby_names</code> на ведущем, подтверждающие сообщения с этого сервера, в совокупности с сообщениями с других синхронных серверов, будут сигналом к завершению ожидания при фиксировании транзакций, требующих подтверждения сохранения записи фиксации. Эти параметры позволяют администратору определить, какие резервные серверы будут синхронными резервными. Заметьте, что настройка синхронной репликации в основном осуществляется на главном сервере. Перечисленные в списке резервных серверы должны быть подключены к нему непосредственно; он ничего не знает о резервных серверах, подключённых каскадно, через промежуточные серверы.</p><p>Если <code class="varname">synchronous_commit</code> имеет значение <code class="literal">remote_write</code>, то в случае подтверждения транзакции ответ от резервного сервера об успешном подтверждении будет передан, когда данные запишутся в операционной системе, но не когда данные будет реально сохранены на диске. При таком значении уровень надёжности снижается по сравнению со значением <code class="literal">on</code>. Резервный сервер может потерять данные в случае падения операционной системы, но не в случае падения <span class="productname">PostgreSQL</span>. Тем не менее этот вариант полезен на практике, так как позволяет сократить время отклика для транзакции. Потеря данных может произойти только в случае одновременного сбоя ведущего и резервного, осложнённого повреждением БД на ведущем.</p><p>Если <code class="varname">synchronous_commit</code> имеет значение <code class="literal">remote_apply</code>, то для завершения фиксирования транзакции потребуется дождаться, чтобы текущие синхронные резервные серверы сообщили, что они воспроизвели транзакцию и её могут видеть запросы пользователей. В простых случаях это позволяет обеспечить обычный уровень согласованности и распределение нагрузки.</p><p>Пользователи прекратят ожидание в случае запроса на быструю остановку сервера. В то время как при использовании асинхронной репликации сервер не будет полностью остановлен, пока все исходящие записи WAL не переместятся на текущий присоединённый резервный сервер.</p></div><div class="sect3" id="SYNCHRONOUS-REPLICATION-MULTIPLE-STANDBYS"><div class="titlepage"><div><div><h4 class="title">27.2.8.2. Несколько синхронных резервных серверов <a href="#SYNCHRONOUS-REPLICATION-MULTIPLE-STANDBYS" class="id_link">#</a></h4></div></div></div><p>Синхронная репликация поддерживает применение одного или нескольких синхронных резервных серверов; транзакции будут ждать, пока все резервные серверы, считающиеся синхронными, не подтвердят получение своих данных. Число синхронных резервных серверов, от которых транзакции должны ждать подтверждения, задаётся в параметре <code class="varname">synchronous_standby_names</code>. В этом параметре также задаётся список имён резервных серверов и метод (<code class="literal">FIRST</code> или <code class="literal">ANY</code>) выбора синхронных из заданного списка.</p><p>С методом <code class="literal">FIRST</code> производится синхронная репликация на основе приоритетов, когда транзакции фиксируются только после того, как их записи в WAL реплицируются на заданное число синхронных резервных серверов, выбираемых согласно приоритетам. Серверы, имена которых идут в начале списка, имеют больший приоритет и выбираются на роль синхронных. Другие резервные серверы, идущие в этом списке за ними, считаются потенциальными синхронными. Если один из текущих синхронных резервных серверов по какой-либо причине отключается, он будет немедленно заменён следующим по порядку резервным сервером.</p><p>Пример значения <code class="varname">synchronous_standby_names</code> для нескольких синхронных резервных серверов, выбираемых по приоритетам: </p><pre class="programlisting">synchronous_standby_names = 'FIRST 2 (s1, s2, s3)'</pre><p> В данном примере, если работают четыре резервных сервера <code class="literal">s1</code>, <code class="literal">s2</code>, <code class="literal">s3</code> и <code class="literal">s4</code>, два сервера <code class="literal">s1</code> и <code class="literal">s2</code> будут выбраны на роль синхронных резервных, так как их имена идут в начале этого списка. Сервер <code class="literal">s3</code> будет потенциальным резервным и возьмёт на себя роль синхронного резервного при отказе <code class="literal">s1</code> или <code class="literal">s2</code>. Сервер <code class="literal">s4</code> будет асинхронным резервным, так как его имя в этом списке отсутствует.</p><p>С методом <code class="literal">ANY</code> производится синхронная репликация на основе кворума, когда транзакции фиксируются только после того, как их записи в WAL реплицируются на <span class="emphasis"><em>как минимум</em></span> заданное число синхронных серверов в списке.</p><p>Пример значения <code class="varname">synchronous_standby_names</code> для нескольких синхронных резервных серверов, образующих кворум: </p><pre class="programlisting">synchronous_standby_names = 'ANY 2 (s1, s2, s3)'</pre><p> В данном примере, если работают четыре резервных сервера <code class="literal">s1</code>, <code class="literal">s2</code>, <code class="literal">s3</code> и <code class="literal">s4</code>, транзакции будут фиксироваться только после получения ответов как минимум от двух резервных серверов из <code class="literal">s1</code>, <code class="literal">s2</code> и <code class="literal">s3</code>. Сервер <code class="literal">s4</code> будет асинхронным резервным, так как его имя в этом списке отсутствует.</p><p>Состояние синхронности резервных серверов можно увидеть в представлении <code class="structname">pg_stat_replication</code>.</p></div><div class="sect3" id="SYNCHRONOUS-REPLICATION-PERFORMANCE"><div class="titlepage"><div><div><h4 class="title">27.2.8.3. Планирование производительности <a href="#SYNCHRONOUS-REPLICATION-PERFORMANCE" class="id_link">#</a></h4></div></div></div><p>Организуя синхронную репликацию, обычно нужно обстоятельно обдумать конфигурацию и размещение резервных серверов, чтобы обеспечить приемлемую производительность приложений. Ожидание не потребляет системные ресурсы, но блокировки транзакций будут сохраняться до подтверждения передачи. Как следствие, непродуманное использование синхронной репликации приведёт к снижению производительности БД из-за увеличения времени отклика и числа конфликтов.</p><p><span class="productname">PostgreSQL</span> позволяет разработчикам выбрать требуемый уровень надёжности, обеспечиваемый при репликации. Он может быть установлен для системы в целом, для отдельного пользователя или соединения или даже для отдельной транзакции.</p><p>Например, в рабочей нагрузке приложения 10% изменений могут относиться к важным данным клиентов, а 90% — к менее критичным данным, потеряв которые, бизнес вполне сможет выжить (например, это могут быть текущие разговоры пользователей между собой).</p><p>При настройке уровня синхронности репликации на уровне приложения (на ведущем) можно задать синхронную репликацию для большинства важных изменений без замедления общего рабочего ритма. Возможность настройки на уровне приложения является важным и практичным средством для получения выгод синхронной репликации при высоком быстродействии.</p><p>Следует иметь в виду, что пропускная способность сети должна быть больше скорости генерирования данных WAL.</p></div><div class="sect3" id="SYNCHRONOUS-REPLICATION-HA"><div class="titlepage"><div><div><h4 class="title">27.2.8.4. Планирование отказоустойчивости <a href="#SYNCHRONOUS-REPLICATION-HA" class="id_link">#</a></h4></div></div></div><p>В <code class="varname">synchronous_standby_names</code> задаётся количество и имена синхронных резервных серверов, от которых будет ожидаться подтверждение при фиксировании транзакции, когда параметру <code class="varname">synchronous_commit</code> присвоено значение <code class="literal">on</code>, <code class="literal">remote_apply</code> или <code class="literal">remote_write</code>. Фиксирование транзакции в таком режиме может не завершиться никогда, если один из синхронных резервных серверов выйдет из строя.</p><p>Поэтому для высокой степени доступности лучше всего обеспечить наличие синхронных резервных серверов в должном количестве. Для этого можно перечислить несколько потенциальных резервных серверов в строке <code class="varname">synchronous_standby_names</code>.</p><p>При синхронной репликации на основе приоритетов синхронными резервными серверами станут серверы, имена которых стоят в этом списке первыми. Следующие за ними серверы будут становиться синхронными резервными при отказе одного из текущих.</p><p>При синхронной репликации на основе кворума кандидатами на роль синхронных резервных будут все серверы в списке. И если один из них откажет, другие серверы будут продолжать исполнять эту роль.</p><p>Когда к ведущему серверу впервые присоединяется резервный, он ещё не будет полностью синхронизированным. Это называется состоянием <code class="literal">навёрстывания</code>. Как только отставание резервного от ведущего сервера сократится до нуля в первый раз, система перейдет в состояние <code class="literal">потоковой передачи</code> в реальном времени. Сразу после создания резервного сервера навёрстывание может быть длительным. В случае выключения резервного сервера длительность этого процесса увеличится соответственно продолжительности простоя. Резервный сервер может стать синхронным только по достижении состояния <code class="literal">потоковой передачи</code>. Это состояние можно проследить в представлении <code class="structname">pg_stat_replication</code>.</p><p>Если ведущий сервер перезапускается при наличии зафиксированных транзакций, ожидающих подтверждения, эти транзакции будут помечены как полностью зафиксированные после восстановления ведущего. При этом нельзя гарантировать, что все резервные серверы успели получить все текущие данные WAL к моменту падения ведущего. Таким образом, некоторые транзакции могут считаться незафиксированными на резервном сервере, даже если они считаются зафиксированными на ведущем. Гарантия, которую мы можем дать, состоит в том, что приложение не получит явного подтверждения успешной фиксации, пока не будет уверенности, что данные WAL получены всеми синхронными резервными серверами.</p><p>Если запустить синхронные резервные серверы в указанном количестве не удаётся, вам следует уменьшить число синхронных серверов, подтверждения которых требуются для завершения фиксации транзакций, в параметре <code class="varname">synchronous_standby_names</code> (или вовсе отключить его) и перезагрузить файл конфигурации на ведущем сервере.</p><p>В случае если ведущий сервер стал недоступным для оставшихся резервных, следует переключиться на наиболее подходящий из имеющихся резервных серверов.</p><p>Если необходимо пересоздать резервный сервер при наличии ожидающих подтверждения транзакций, функции <code class="function">pg_backup_start()</code> и <code class="function">pg_backup_stop()</code> нужно вызывать в сеансе с параметром <code class="varname">synchronous_commit</code> = <code class="literal">off</code>, в противном случае эти запросы будут бесконечно ждать появления резервного сервера.</p></div></div><div class="sect2" id="CONTINUOUS-ARCHIVING-IN-STANDBY"><div class="titlepage"><div><div><h3 class="title">27.2.9. Непрерывное архивирование на резервном сервере <a href="#CONTINUOUS-ARCHIVING-IN-STANDBY" class="id_link">#</a></h3></div></div></div><a id="id-1.6.14.16.21.2" class="indexterm"></a><p>Когда на резервном сервере применяется непрерывное архивирование WAL, возможны два различных сценария: архив WAL может быть общим для ведущего и резервного сервера, либо резервный сервер может иметь собственный архив WAL. Когда резервный работает с собственным архивом WAL, установите в <code class="varname">archive_mode</code> значение <code class="literal">always</code>, и он будет вызывать команду архивации для каждого сегмента WAL, который он получает при восстановлении из архива или потоковой репликации. В случае с общим архивом можно поступить аналогично, но <code class="varname">archive_command</code> или <code class="varname">archive_library</code> должна проверять, нет ли в архиве файла, идентичного архивируемому. Таким образом, команда <code class="varname">archive_command</code> или библиотека <code class="varname">archive_library</code> должна позаботиться о том, чтобы существующий файл не был заменён файлом с другим содержимым, а в случае попытки повторного архивирования должна сообщать об успешном выполнении. При этом все эти действия должны быть рассчитаны на условия гонки, возможные, если два сервера попытаются архивировать один и тот же файл одновременно.</p><p>Если в <code class="varname">archive_mode</code> установлено значение <code class="literal">on</code>, архивация в режиме восстановления или резерва не производится. В случае повышения резервного сервера, он начнёт архивацию после повышения, но в архив не попадут те файлы WAL или файлы истории линии времени, которые генерировал не он сам. Поэтому, чтобы в архиве оказался полный набор файлов WAL, необходимо обеспечить архивацию всех файлов WAL до того, как они попадут на резервный сервер. Это естественным образом происходит при трансляции файлов журналов, так как резервный сервер может восстановить только файлы, которые находятся в архиве, однако при потоковой репликации это не так. Когда сервер работает не в режиме резерва, различий между режимами <code class="literal">on</code> и <code class="literal">always</code> нет.</p></div></div><div class="navfooter"><hr /><table width="100%" summary="Navigation footer"><tr><td width="40%" align="left"><a accesskey="p" href="different-replication-solutions.html" title="27.1. Сравнение различных решений">Пред.</a> </td><td width="20%" align="center"><a accesskey="u" href="high-availability.html" title="Глава 27. Отказоустойчивость, балансировка нагрузки и репликация">Наверх</a></td><td width="40%" align="right"> <a accesskey="n" href="warm-standby-failover.html" title="27.3. Отработка отказа">След.</a></td></tr><tr><td width="40%" align="left" valign="top">27.1. Сравнение различных решений </td><td width="20%" align="center"><a accesskey="h" href="index.html" title="Документация к PostgreSQL 16.3">Начало</a></td><td width="40%" align="right" valign="top"> 27.3. Отработка отказа</td></tr></table></div></body></html>